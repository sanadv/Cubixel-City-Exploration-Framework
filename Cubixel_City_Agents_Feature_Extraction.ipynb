{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPlWQmn82JlET3lgSZb/a35",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanadv/Cubixel-City-Exploration-Framework/blob/main/Cubixel_City_Agents_Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_fscore_support\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize the pixel values\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Cubixel Transformation\n",
        "def cubixel_transform(image):\n",
        "    cubixels = np.zeros((image.shape[0], image.shape[1], 3))\n",
        "    for i in range(image.shape[0]):\n",
        "        for j in range(image.shape[1]):\n",
        "            R, G, B = image[i, j]\n",
        "            cubixels[i, j] = [R, G, B]  # Cubixel dimensions (R,G,B)\n",
        "    return cubixels\n",
        "\n",
        "# VoV Computation\n",
        "def compute_vov(cubixels):\n",
        "    VoV = np.zeros((cubixels.shape[0], cubixels.shape[1]))\n",
        "    for i in range(1, cubixels.shape[0] - 1):\n",
        "        for j in range(1, cubixels.shape[1] - 1):\n",
        "            current_vol = np.prod(cubixels[i, j])\n",
        "            neighbors = [\n",
        "                np.prod(cubixels[i - 1, j]), np.prod(cubixels[i + 1, j]),\n",
        "                np.prod(cubixels[i, j - 1]), np.prod(cubixels[i, j + 1])\n",
        "            ]\n",
        "            VoV[i, j] = np.sum(np.abs(np.array(neighbors) - current_vol))\n",
        "    return VoV\n",
        "\n",
        "# Agent Class for Exploring VoV Map\n",
        "class Agent:\n",
        "    def __init__(self, grid, start_pos=(0, 0)):\n",
        "        self.grid = grid  # VoV map\n",
        "        self.position = start_pos\n",
        "        self.explored = set()\n",
        "\n",
        "    def move(self):\n",
        "        x, y = self.position\n",
        "        neighbors = [(x - 1, y), (x + 1, y), (x, y - 1), (x, y + 1)]\n",
        "        valid_neighbors = [(i, j) for i, j in neighbors if 0 <= i < self.grid.shape[0] and 0 <= j < self.grid.shape[1]]\n",
        "\n",
        "        # Move to the neighbor with the highest VoV\n",
        "        best_move = max(valid_neighbors, key=lambda pos: self.grid[pos])\n",
        "        self.position = best_move\n",
        "        self.explored.add(best_move)\n",
        "        return best_move\n",
        "\n",
        "    def explore(self, steps=100):\n",
        "        path = []\n",
        "        for _ in range(steps):\n",
        "            next_pos = self.move()\n",
        "            path.append(next_pos)\n",
        "        return path\n",
        "\n",
        "# Extract Features using Cubixel and VoV + Agent\n",
        "def extract_features(image):\n",
        "    cubixels = cubixel_transform(image)\n",
        "    vov_map = compute_vov(cubixels)\n",
        "\n",
        "    # Initialize agent and explore\n",
        "    agent = Agent(vov_map)\n",
        "    path = agent.explore(steps=50)\n",
        "\n",
        "    # Create a feature map combining local VoV and agent exploration\n",
        "    feature_map = np.zeros_like(vov_map)\n",
        "    for x, y in path:\n",
        "        feature_map[x, y] = vov_map[x, y]  # Mark agent path\n",
        "\n",
        "    # Combine VoV map and agent exploration map as hybrid features\n",
        "    hybrid_features = np.stack([vov_map, feature_map], axis=-1)\n",
        "    return hybrid_features\n",
        "\n",
        "# Apply feature extraction to the entire dataset\n",
        "def transform_dataset(dataset):\n",
        "    transformed_dataset = []\n",
        "    for image in dataset:\n",
        "        features = extract_features(image)\n",
        "        transformed_dataset.append(features)\n",
        "    return np.array(transformed_dataset)\n",
        "\n",
        "# Transform training and testing datasets\n",
        "x_train_transformed = transform_dataset(x_train)\n",
        "x_test_transformed = transform_dataset(x_test)\n",
        "\n",
        "# Define the CNN model\n",
        "def build_cnn_model():\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Input shape: (32, 32, 2) because we have 2 feature maps (VoV and agent-based map)\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 2)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))  # 10 classes for CIFAR-10\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Custom callback to compute additional metrics after training\n",
        "class MetricsCallback(Callback):\n",
        "    def on_train_end(self, logs=None):\n",
        "        # Training predictions\n",
        "        y_train_pred = np.argmax(self.model.predict(x_train_transformed), axis=-1)\n",
        "        y_train_true = np.argmax(y_train, axis=-1)\n",
        "\n",
        "        # Testing predictions\n",
        "        y_test_pred = np.argmax(self.model.predict(x_test_transformed), axis=-1)\n",
        "        y_test_true = np.argmax(y_test, axis=-1)\n",
        "\n",
        "        # Training metrics\n",
        "        train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(y_train_true, y_train_pred, average='macro')\n",
        "        train_auc = roc_auc_score(y_train, self.model.predict(x_train_transformed), multi_class='ovr')\n",
        "        train_loss, train_acc = self.model.evaluate(x_train_transformed, y_train, verbose=0)\n",
        "\n",
        "        # Testing metrics\n",
        "        test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(y_test_true, y_test_pred, average='macro')\n",
        "        test_auc = roc_auc_score(y_test, self.model.predict(x_test_transformed), multi_class='ovr')\n",
        "        test_loss, test_acc = self.model.evaluate(x_test_transformed, y_test, verbose=0)\n",
        "\n",
        "        # Print the results\n",
        "        print(\"\\nTraining Metrics:\")\n",
        "        print(f\"Loss: {train_loss:.4f}, Accuracy: {train_acc * 100:.2f}%\")\n",
        "        print(f\"Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1-score: {train_f1:.4f}, AUC: {train_auc:.4f}\")\n",
        "\n",
        "        print(\"\\nTesting Metrics:\")\n",
        "        print(f\"Loss: {test_loss:.4f}, Accuracy: {test_acc * 100:.2f}%\")\n",
        "        print(f\"Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1-score: {test_f1:.4f}, AUC: {test_auc:.4f}\")\n",
        "\n",
        "# Build the model\n",
        "model = build_cnn_model()\n",
        "\n",
        "# Train the model with custom callback\n",
        "metrics_callback = MetricsCallback()\n",
        "history = model.fit(x_train_transformed, y_train, epochs=50, batch_size=64, validation_data=(x_test_transformed, y_test), callbacks=[metrics_callback])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(x_test_transformed, y_test)\n",
        "print(f'\\nFinal Test accuracy: {test_acc * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "AppDk7y3OtOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_fscore_support\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape to add a single grayscale channel\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "# Normalize the pixel values\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Cubixel Transformation for Grayscale Images\n",
        "def cubixel_transform(image):\n",
        "    cubixels = np.zeros((image.shape[0], image.shape[1], 1))  # Only one channel for grayscale\n",
        "    for i in range(image.shape[0]):\n",
        "        for j in range(image.shape[1]):\n",
        "            pixel_value = image[i, j, 0]  # Grayscale pixel value\n",
        "            cubixels[i, j] = [pixel_value]  # Single cubixel dimension (Grayscale)\n",
        "    return cubixels\n",
        "\n",
        "# VoV Computation\n",
        "def compute_vov(cubixels):\n",
        "    VoV = np.zeros((cubixels.shape[0], cubixels.shape[1]))\n",
        "    for i in range(1, cubixels.shape[0] - 1):\n",
        "        for j in range(1, cubixels.shape[1] - 1):\n",
        "            current_vol = np.prod(cubixels[i, j])\n",
        "            neighbors = [\n",
        "                np.prod(cubixels[i - 1, j]), np.prod(cubixels[i + 1, j]),\n",
        "                np.prod(cubixels[i, j - 1]), np.prod(cubixels[i, j + 1])\n",
        "            ]\n",
        "            VoV[i, j] = np.sum(np.abs(np.array(neighbors) - current_vol))\n",
        "    return VoV\n",
        "\n",
        "# Agent Class for Exploring VoV Map\n",
        "class Agent:\n",
        "    def __init__(self, grid, start_pos=(0, 0)):\n",
        "        self.grid = grid  # VoV map\n",
        "        self.position = start_pos\n",
        "        self.explored = set()\n",
        "\n",
        "    def move(self):\n",
        "        x, y = self.position\n",
        "        neighbors = [(x - 1, y), (x + 1, y), (x, y - 1), (x, y + 1)]\n",
        "        valid_neighbors = [(i, j) for i, j in neighbors if 0 <= i < self.grid.shape[0] and 0 <= j < self.grid.shape[1]]\n",
        "\n",
        "        # Move to the neighbor with the highest VoV\n",
        "        best_move = max(valid_neighbors, key=lambda pos: self.grid[pos])\n",
        "        self.position = best_move\n",
        "        self.explored.add(best_move)\n",
        "        return best_move\n",
        "\n",
        "    def explore(self, steps=100):\n",
        "        path = []\n",
        "        for _ in range(steps):\n",
        "            next_pos = self.move()\n",
        "            path.append(next_pos)\n",
        "        return path\n",
        "\n",
        "# Extract Features using Cubixel and VoV + Agent\n",
        "def extract_features(image):\n",
        "    cubixels = cubixel_transform(image)\n",
        "    vov_map = compute_vov(cubixels)\n",
        "\n",
        "    # Initialize agent and explore\n",
        "    agent = Agent(vov_map)\n",
        "    path = agent.explore(steps=50)\n",
        "\n",
        "    # Create a feature map combining local VoV and agent exploration\n",
        "    feature_map = np.zeros_like(vov_map)\n",
        "    for x, y in path:\n",
        "        feature_map[x, y] = vov_map[x, y]  # Mark agent path\n",
        "\n",
        "    # Combine VoV map and agent exploration map as hybrid features\n",
        "    hybrid_features = np.stack([vov_map, feature_map], axis=-1)\n",
        "    return hybrid_features\n",
        "\n",
        "# Apply feature extraction to the entire dataset\n",
        "def transform_dataset(dataset):\n",
        "    transformed_dataset = []\n",
        "    for image in dataset:\n",
        "        features = extract_features(image)\n",
        "        transformed_dataset.append(features)\n",
        "    return np.array(transformed_dataset)\n",
        "\n",
        "# Transform training and testing datasets\n",
        "x_train_transformed = transform_dataset(x_train)\n",
        "x_test_transformed = transform_dataset(x_test)\n",
        "\n",
        "# Define the CNN model\n",
        "def build_cnn_model():\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Input shape: (28, 28, 2) because we have 2 feature maps (VoV and agent-based map)\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 2)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))  # 10 classes for MNIST\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Custom callback to compute additional metrics after training\n",
        "class MetricsCallback(Callback):\n",
        "    def on_train_end(self, logs=None):\n",
        "        # Training predictions\n",
        "        y_train_pred = np.argmax(self.model.predict(x_train_transformed), axis=-1)\n",
        "        y_train_true = np.argmax(y_train, axis=-1)\n",
        "\n",
        "        # Testing predictions\n",
        "        y_test_pred = np.argmax(self.model.predict(x_test_transformed), axis=-1)\n",
        "        y_test_true = np.argmax(y_test, axis=-1)\n",
        "\n",
        "        # Training metrics\n",
        "        train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(y_train_true, y_train_pred, average='macro')\n",
        "        train_auc = roc_auc_score(y_train, self.model.predict(x_train_transformed), multi_class='ovr')\n",
        "        train_loss, train_acc = self.model.evaluate(x_train_transformed, y_train, verbose=0)\n",
        "\n",
        "        # Testing metrics\n",
        "        test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(y_test_true, y_test_pred, average='macro')\n",
        "        test_auc = roc_auc_score(y_test, self.model.predict(x_test_transformed), multi_class='ovr')\n",
        "        test_loss, test_acc = self.model.evaluate(x_test_transformed, y_test, verbose=0)\n",
        "\n",
        "        # Print the results\n",
        "        print(\"\\nTraining Metrics:\")\n",
        "        print(f\"Loss: {train_loss:.4f}, Accuracy: {train_acc * 100:.2f}%\")\n",
        "        print(f\"Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1-score: {train_f1:.4f}, AUC: {train_auc:.4f}\")\n",
        "\n",
        "        print(\"\\nTesting Metrics:\")\n",
        "        print(f\"Loss: {test_loss:.4f}, Accuracy: {test_acc * 100:.2f}%\")\n",
        "        print(f\"Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1-score: {test_f1:.4f}, AUC: {test_auc:.4f}\")\n",
        "\n",
        "# Build the model\n",
        "model = build_cnn_model()\n",
        "\n",
        "# Train the model with custom callback\n",
        "metrics_callback = MetricsCallback()\n",
        "history = model.fit(x_train_transformed, y_train, epochs=50, batch_size=64, validation_data=(x_test_transformed, y_test), callbacks=[metrics_callback])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(x_test_transformed, y_test)\n",
        "print(f'\\nFinal Test accuracy: {test_acc * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "vHLheokxaVoq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}